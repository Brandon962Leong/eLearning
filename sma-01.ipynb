{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img alt=\"\" src=\"images/cover_sma.jpg\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">Pendahuluan Digital Data Gathering</font><br> <b>(C) Taufik Sutanto - 2020<br>https://tau-data.id/sma-01/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline:\n",
    "\n",
    "1. Social Media Crawling\n",
    "2. Social Media Streaming\n",
    "3. Sekilas Privacy & Ethics Data Gathering\n",
    "4. Scrapping Media Social & Website\n",
    "5. Loading Local Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hanya jalankan jika menggunakan Google Colab\n",
    "# Jika menjalankan program ini secara lokal (Anaconda/WinPython) sebaiknya dijalankan di Terminal/Command Prompt\n",
    "\n",
    "!pip install unidecode twython tweepy beautifulsoup4 tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import tweepy, json, nltk, urllib.request, requests\n",
    "from urllib.request import Request, urlopen\n",
    "from twython import TwythonStreamer\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering: Crawling, Streaming, Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Analytics (SMA)\n",
    "\n",
    "<h3 id=\"SMA-adalah-sebuah-proses-pengumpulan-data-dari-media-sosial-dan-analisanya-untuk-mendapatkan-'insights'-atau-informasi-berharga-untuk-suatu-tujuan-tertentu-(definisi-adopted-dari-Gartner*)\">SMA adalah sebuah proses pengumpulan data dari media sosial dan analisanya untuk mendapatkan &#39;insights&#39; atau informasi berharga untuk suatu tujuan tertentu (definisi diadopsi dari Gartner*).</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/8_SMA.JPG\" style=\"width: 600px; height: 304px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/8_SMA_Cycle.JPG\" style=\"height:300px; width:705px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/8_SMA_Techniques.JPG\" style=\"height:400px; width:574px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Crawling-Data\">Crawling/Scrapping Data</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/Digital_Media_Crawling_.png\" /></p>\n",
    "\n",
    "* Credits, image source: https://www.promptcloud.com/blog/scraping-social-media-data-for-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Social-Media-Analytics-Challenges\"><u>Tantangan Social Media Analytics</u></h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>\n",
    "\t<p>Pendek (<strong>Short </strong>in lengths): bahkan terkadang tidak mengandung sebuah kalimat yang utuh menurut tata bahasa (grammar).</p>\n",
    "\t</li>\n",
    "\t<li><strong>Noise&nbsp;</strong>: Data media sosial penuh dengan noise seperti typos (salah ketik), encoding yang tidak jamak, slang, dsb.</li>\n",
    "\t<li><strong>Temporal&nbsp;</strong>: Informasi yang sedang trending biasanya hanya sesaat,<br />\n",
    "\tsehingga SMA diharapkan dilakukan dengan cepat menggunakan model-model/teknik-teknik analisa data yang efisien.</li>\n",
    "\t<li><strong>High-dimensional</strong> : Data di Media Sosial (Teks, Gambar, Video, Suara, dsb) adalah data tidak terstruktur berdimensi tinggi.</li>\n",
    "\t<li><strong>Fine-grained</strong> : Data di media sosial berasal dari banyak user yang masing-masingnya bisa jadi membahas beberapa topik yang berbeda.<br />\n",
    "\tSehingga komunitas (kelompok), topik, maupun klasifikasi yang ada menjadi besar (fine-grained).</li>\n",
    "\t<li><strong>Large in volume</strong>&nbsp;&amp; <strong>High velocity</strong>:&nbsp; Data yang sangat besar dan bertambah besar dengan cepat.</li>\n",
    "\t<li><strong>A lot of external Information</strong> : Informasi terkadang lebih banyak terkandung dari luar (eksternal) seperti url website, video, atau hal lain yang dibagikan oleh pengguna media sosial.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Case-Study:-twitter\">Case Study: twitter</h2>\n",
    "<ol>\n",
    "\t<li>API Keys</li>\n",
    "\t<li>Rules</li>\n",
    "\t<li>Crawling by searching</li>\n",
    "    <li>tweet Json</li>\n",
    "\t<li>Crawling by Streaming and Scrapping</li>\n",
    "    <li>twitter Social Media Analytics</li>\n",
    "</ol>\n",
    "<img alt=\"\" src=\"images/6_twitter.png\" style=\"width: 300px; height: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>twitter API Keys</h2>\n",
    "\n",
    "<h2><img alt=\"\" src=\"images/6_Creating_API_Keys.png\" style=\"width: 854px ; height: 444px\" /></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Aturan-twitter\">Aturan, bentuk data, &amp; error codes twitter</h2>\n",
    "\n",
    "<ol>\n",
    "\t<li>\n",
    "\t<p><a href=\"https://dev.twitter.com/rest/public/rate-limiting\" target=\"_blank\">https://</a><a href=\"https://dev.twitter.com/rest/public/rate-limiting\" target=\"_blank\">dev.twitter.com/rest/public/rate-limiting</a></p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p><a href=\"https://dev.twitter.com/overview/terms/agreement-and-policy\" target=\"_blank\">https://dev.twitter.com/overview/terms/agreement-and-policy</a></p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p><a href=\"https://dev.twitter.com/overview/api/response-codes\" target=\"_blank\">https://</a><a href=\"https://dev.twitter.com/overview/api/response-codes\" target=\"_blank\">dev.twitter.com/overview/api/response-codes</a></p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p><a href=\"https://dev.twitter.com/overview/api/tweets\" target=\"_blank\">https://</a><a href=\"https://dev.twitter.com/overview/api/tweets\" target=\"_blank\">dev.twitter.com/overview/api/tweets</a></p>\n",
    "\t</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh API Keys (Sesuaikan dengan API keys masing-masing)\n",
    "Ck = '' # consumer_key\n",
    "Cs = '' # consumer_secret\n",
    "At = '-' # access_token\n",
    "As = '' # access_secret\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_connect(Ck, Cs, At, As, verbose = 0):\n",
    "    try:\n",
    "        auth = tweepy.OAuthHandler(Ck, Cs)\n",
    "        auth.set_access_token(At, As)\n",
    "        twitter = tweepy.API(auth, timeout=120)\n",
    "        if verbose != 0:\n",
    "            user = twitter.verify_credentials()\n",
    "            print('Welcome \"%s\" you are now connected to twitter server' %user.name)\n",
    "        return twitter\n",
    "    except:\n",
    "        print(\"Connection failed, please check your API keys or connection\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koneksi ke twitter\n",
    "twitter = twitter_connect(Ck, Cs, At, As, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Json-Files\">Json Files</h2>\n",
    "\n",
    "<ul>\n",
    "\t<li>Populer digunakan untuk data dari Media Sosial dan NoSQL</li>\n",
    "\t<li>Portable: File Json memuat nama variabel dan nilainya (tidak seperti XML)</li>\n",
    "\t<li>Plain Text</li>\n",
    "\t<li>Schemaless: Setiap record tidak harus memiliki jumlah field yang tetap seperti csv</li>\n",
    "\t<li>JSON isomorfis dengan &quot;Dictionary&quot; di Python</li>\n",
    "\t<li>Contoh struktur file json:</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/json.png\" style=\"width: 200px; height: 211px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max 100 tweet per \"API call\"\n",
    "topic = 'data indonesia'\n",
    "N = 100 # jumlah tweet yang ingin diambil\n",
    "bahasa = 'id'\n",
    "T = twitter.search(q=topic, lang=bahasa, count=N, tweet_mode = 'extended')\n",
    "tweets = [t._json for t in T]\n",
    "print(' Berhasil mendapatkan {} tweets'.format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Datanya berbentuk JSON\n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh mengakses data spesifik pada tweet yang pertama:\n",
    "print('tweet pertama oleh \"{}\" : \"{}\"'.format(tweets[0]['user']['screen_name'],tweets[0]['full_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagaimana kalau mau mengambil data lebih banyak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next data\n",
    "last_id = T[-1]._json['id'] - 1\n",
    "last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = twitter.search(q=topic, lang=bahasa, count=N, tweet_mode = 'extended', max_id=last_id)\n",
    "tweets.extend([t._json for t in T])\n",
    "\n",
    "print('Jumlah data sekarang = ', len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lalu Loop terus sampai \"T\" False (kosong/None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menyimpan hasil crawling? (Sebaiknya di NoSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTweets(tweets, file='Tweets.json'): #in Json Format\n",
    "    with open(file, 'w') as f:\n",
    "        for t in tweets:\n",
    "            try:\n",
    "                f.write(json.dumps(t)+'\\n')\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan hasil crawling twitter\n",
    "fileName = 'data/tweets_sma-01.json'\n",
    "saveTweets(tweets,file=fileName)\n",
    "print('Saved to '+fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Kembali?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTweets(file='Tweets.json'):\n",
    "    f=open(file,encoding='utf-8', errors ='ignore', mode='r')\n",
    "    T=f.readlines();f.close()\n",
    "    for i,t in enumerate(T):\n",
    "        T[i] = json.loads(t.strip())\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me-load kembali jika (misal) analisa ingin dilakukan di lain waktu\n",
    "# Sengaja nama variabelnya saya bedakan (T2)\n",
    "T2 = loadTweets(file='data/tweets_sma-01.json')\n",
    "print('tweet pertama oleh \"{}\" : \"{}\"'.format(T2[0]['user']['screen_name'],T2[0]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh mengambil hanya data tweet\n",
    "D = [t['full_text'] for t in T2]\n",
    "D[:5] # 5 tweet pertama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemilihan KeyWords yang baik\n",
    "\n",
    "### https://medium.com/lingvo-masino/how-to-choose-keywords-in-twitter-9c3b85c50290\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Operator (penting)\n",
    "\n",
    "<ul>\n",
    "\t<li><img alt=\"\" src=\"images/query_Operator.png\" style=\"width: 661px; height: 554px;\" /></li>\n",
    "    <li>Detail: <a href=\"https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators.html\" target=\"_blank\">https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators.html</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita coba #1\n",
    "twitter = twitter_connect(Ck, Cs, At, As)\n",
    "topic = 'from:taudataid'\n",
    "n = 10 # Contoh jumlah tweet yang ingin diambil\n",
    "T = twitter.search(q=topic, lang=bahasa, count=N, tweet_mode = 'extended')\n",
    "tweets = [t._json for t in T]\n",
    "isiTweet = [t['full_text'] for t in tweets]\n",
    "isiTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go to: https://www.latlong.net/convert-address-to-lat-long.html\n",
    "\n",
    "## Get Latitude dan Longitude dari alamat yang diinginkan\n",
    "\n",
    "**Catt**: Proses ini bisa juga digantikan dengan Google Maps API (gratis 40.000 query/bulan) dan bisa dijalankan langsung dalam program Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita coba #3 gunakan google (map) untuk koordinat suatu lokasi\n",
    "# http://thoughtfaucet.com/search-twitter-by-location/\n",
    "# misal search tweet tentang \"makanan\" di Depok dan sekitarnya\n",
    "\n",
    "auth = tweepy.auth.OAuthHandler(Ck, Cs)\n",
    "auth.set_access_token(At, As)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "Geo, N = \"-6.402484,106.794243,30km\", 5  # HAti-hati jangan ada spasi di Lat-Lon-Radius\n",
    "qry = 'makanan'\n",
    "for tweet in tweepy.Cursor(api.search, q=qry, count=100, geocode=Geo).items(N):\n",
    "    print([tweet.created_at, tweet.text.encode('utf-8'), tweet.user.id, tweet.geo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Streaming-Data\">Streaming and Scrapping Data</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/Meme_Streaming_Data.jpg\" style=\"width: 307px; height: 309px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming tweets. Untuk percobaan pilih topicS sesuatu yg sedang trending/populer \"saat ini\".\n",
    "# Atau bisa coba dengan mengirim tweet sendiri :)\n",
    "def streamTwitter(topicS, lang):\n",
    "    class MyStreamer(TwythonStreamer):\n",
    "        def on_success(self, data):\n",
    "            global count\n",
    "            count+=1\n",
    "            print('tweet from {}, post: {}'.format(data['user']['screen_name'], data['text']))\n",
    "            if count==maxTweet:\n",
    "                print('\\nFinished streaming %.0f tweets' %(maxTweet)); self.disconnect()\n",
    "        def on_error(self, status_code, data):\n",
    "            print('Error Status = %s' %status_code); self.disconnect()\n",
    "\n",
    "    while count<maxTweet:\n",
    "        stream = MyStreamer(Ck, Cs, At, As)\n",
    "        stream.statuses.filter(track=topicS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTweet, count = 2, 0 # Rubah sesuai dengan kebutuhan, Untuk percobaan ini cukup (misal) 3 tweet\n",
    "lang = set(['en','id']) # bahasa bisa dipilih > 1\n",
    "topicS = ['indonesia'] # Bisa>1\n",
    "\n",
    "streamTwitter(topicS, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering Ethics-Regulation\n",
    "\n",
    "* RUU PDP + ITE\n",
    "* ToS\n",
    "* Robots.txt\n",
    "* Consent\n",
    "\n",
    "### https://tau-data.id/scraping/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping \n",
    "\n",
    "1. Go to: https://twitter.com/search-advanced \n",
    "2. Search sesuai keinginan/kebutuhan\n",
    "3. Copy URL\n",
    "4. Ikuti instruksi dibawah\n",
    "\n",
    "### Silahkan Loop dan Modifikasi seperlunya, tapi hormati robots.txt twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server tidak suka request tanpa \"header\"/identifier\n",
    "\n",
    "h = {'User-Agent' : \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"}\n",
    "url = 'https://twitter.com/search?q=data%20science%20until%3A2020-10-17%20since%3A2019-01-18&src=typed_query'\n",
    "\n",
    "req = Request(url, headers = h)\n",
    "resp = urlopen(req).read()\n",
    "soup = bs(resp,'html.parser')\n",
    "Tweets = soup.find_all(class_= 'tweet-text')\n",
    "Tweets = [bs(str(t), \"lxml\").text for t in Tweets]\n",
    "print(Tweets[0], Tweets[1], sep='\\n') # Print 2 pertama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "URL = 'https://fst.uinjkt.ac.id/'\n",
    "Doc = urllib.request.urlopen(URL).read()\n",
    "Doc = bs(Doc,'lxml').text\n",
    "print(Doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Local Documents\n",
    "\n",
    "1. Instalasi Java\n",
    " - JDK 8 ... ingat harus JDK 8\n",
    " - https://www.oracle.com/id/java/technologies/javase/javase-jdk8-downloads.html\n",
    " - Set Java Home Directory\n",
    "2. Instalasi Tika Server :\n",
    " - Download Tika App Executable Java Jar: https://www.apache.org/dyn/closer.cgi/tika/tika-app-1.24.1.jar\n",
    " - Put in Python home directory\n",
    "3. Instalasi Module Python Tika\n",
    "4. Reading pdf Files (Python Code below)\n",
    "\n",
    "### Tika can read Pdf, DocX, PPTX, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser#, unpack\n",
    "\n",
    "def readDocs(file):\n",
    "    if 'pdf' in file:\n",
    "        headers = {'X-Tika-PDFextractInlineImages': 'true',} \n",
    "        raw = parser.from_file(file, headers=headers)\n",
    "    else:\n",
    "        raw = parser.from_file(file)\n",
    "    if 'content' in raw.keys():\n",
    "        return raw['content']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    doc = readDocs('data/contoh.pdf')\n",
    "except:\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/contoh.pdf\n",
    "    doc = readDocs('data/contoh.pdf')\n",
    "    \n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> End of Module\n",
    "\n",
    "<hr />\n",
    "<p><img alt=\"\" src=\"images/1_meme.jpg\" /></p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
