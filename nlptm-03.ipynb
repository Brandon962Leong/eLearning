{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><strong>Natural Language Processing and Text Mining (NLPTM)<br> Unstructured Data Analysis (UDA)*</strong></center>\n",
    "    \n",
    "## <center><strong><font color=\"blue\">NLPTM-03: Dasar-Dasar Natural Language Processing (NLP)- Bagian ke-03</font></strong></center>\n",
    "<center><img alt=\"\" src=\"images/SocMed.png\"/> </center>\n",
    "    \n",
    "## <center>(C) Taufik Sutanto - 2020 <br><strong><font color=\"blue\"> tau-data Indonesia ~ https://tau-data.id/uda/</font></strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline Module NLPTM-03/UDA-03:\n",
    "* Pos tag \n",
    "* WordNet dan WSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Jalankan Cell ini \"HANYA\" jika anda menggunakan Google Colab\n",
    "# Jika di jalankan di komputer local, silahkan lihat NLPTM-02 untuk instalasinya.\n",
    "import nltk\n",
    "\n",
    "!wget https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/taudataNlpTm.py\n",
    "!mkdir data\n",
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/slang.txt\n",
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_id.txt\n",
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_en.txt\n",
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-ind-def.tab\n",
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-msa-all.tab\n",
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/all_indo_man_tag_corpus_model.crf.tagger\n",
    "\n",
    "!pip install spacy python-crfsuite unidecode textblob sastrawi\n",
    "!python -m spacy download en\n",
    "!python -m spacy download xx\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenisasi\n",
    "\n",
    "<p>Tokenisasi adalah pemisahan kata, simbol, frase, dan entitas penting lainnya (yang disebut sebagai token) dari sebuah teks untuk kemudian di analisa lebih lanjut. Token dalam NLP sering dimaknai dengan &quot;sebuah kata&quot;, walau tokenisasi juga bisa dilakukan ke kalimat, paragraf, atau entitas penting lainnya (misal suatu pola string DNA di Bioinformatika).</p>\n",
    "\n",
    "<p><strong>Mengapa perlu tokenisasi?</strong></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Langkah penting dalam preprocessing, menghindari kompleksitas mengolah langsung pada string asal.</li>\n",
    "\t<li>Menghindari masalah (semantic) saat pemrosesan model-model natural language.</li>\n",
    "\t<li>Suatu tahapan sistematis dalam merubah unstructured (text) data ke bentuk terstruktur yang lebih mudah di olah.</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"images\\2_Pipeline_Tokenization.png\" style=\"height:300px; width:768px\" /><br />\n",
    "[<a href=\"https://www.softwareadvice.com/resources/what-is-text-analytics/\" target=\"_blank\"><strong>Image Source</strong></a>]: https://www.softwareadvice.com/resources/what-is-text-analytics/</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color=\"blue\">Stemming dan Lemma</font>\n",
    "\n",
    "<ol>\n",
    "\t<li>\n",
    "\t<p><strong>Stemmer</strong>&nbsp;akan menghasilkan sebuah bentuk kata yang disepakati oleh suatu sistem tanpa mengindahkan konteks kalimat. Syaratnya beberapa kata dengan makna serupa hanya perlu dipetakan secara konsisten ke sebuah kata baku.&nbsp;Banyak digunakan di IR &amp;&nbsp;komputasinya relatif sedikit. Biasanya dilakukan dengan menghilangkan imbuhan (suffix/prefix).</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p><strong>lemmatisation</strong> akan menghasilkan kata baku (dictionary word) dan bergantung konteks.</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p>Lemma &amp; stemming bisa jadi sama-sama menghasilkan suatu akar kata (root word). Misal : <em>Melompat </em>==&gt; <em>lompat</em></p>\n",
    "\t</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part-of-Speech (pos) di ilmu bahasa (Linguistik)\n",
    "<p><img alt=\"\" src=\"images/2_parts-of-speech-chart.jpg\" style=\"height:400px; width:404px\" /></p>\n",
    "<p>[<a href=\"https://www.paperrater.com/page/parts-of-speech\" target=\"_blank\">image source</a>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# POS tags in NLTK (English)\n",
    "import nltk\n",
    "T = 'I am currently learning NLP in English, but if possible I want to know NLP in Indonesian language too'\n",
    "\n",
    "nltk_tokens = nltk.word_tokenize(T)\n",
    "print(nltk.pos_tag(nltk_tokens))\n",
    "# Tidak lagi hanya 9 macam tags seperti yang dibahas ahli bahasa (linguist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Z = nltk.pos_tag(nltk_tokens)\n",
    "Z[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# filtering berdasarkan \"pos\"\n",
    "pos = ['NN','JJ']\n",
    "hasil = []\n",
    "for pt in Z:\n",
    "    if pt[1] in pos:\n",
    "        hasil.append(pt[0])\n",
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Pythonista! .... Flat.\n",
    "[t for t in Z if t[1] in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Penggunaan di text mining jika suatu kata ingin dibedakan jika berbeda pos\n",
    "hasil = []\n",
    "for pt in Z:\n",
    "    hasil.append(pt[0]+'_'+pt[1])\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Daftar NLTK pos-tags:\n",
    "<img alt=\"\" src=\"images/2_post_tags_NLTK.png\" style=\"height:400px; width:516px\" /></h3>\n",
    "\n",
    "<p>[<a href=\"http://gitqwerty777.github.io/natural-language-processing/\" target=\"_blank\">image source</a>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pos tags in TextBlob (English)\n",
    "from textblob import TextBlob\n",
    "\n",
    "for word, pos in TextBlob(T).tags:\n",
    "    print(word, pos, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pos Tag Spacy English\n",
    "#from spacy.lang.en import English\n",
    "#nlp_en = English()\n",
    "import spacy\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "tokens = nlp_en(T)\n",
    "for tok in tokens:\n",
    "    print(tok, tok.tag_, end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Spacy tidak perlu tabel pos tag ...  bisa pakai perintah \"explain\"\n",
    "spacy.explain('NNP')\n",
    "# Daftar Lengkap: https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pos Tags in Spacy - Bahasa Indonesia?\n",
    "from spacy.lang.id import Indonesian\n",
    "nlp_id = Indonesian()  # Language Model\n",
    "\n",
    "Ti = \"Saat bepergian ke Jogjakarta jangan lupa membeli oleh-oleh\"\n",
    "Teks = nlp_id(Ti)\n",
    "for token in Teks:\n",
    "    print(token.lemma_, token.tag_)\n",
    "# Fungsi pos-tags belum tersedia untuk bahasa indonesia .. :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pos Tag Bahasa Indonesia lewat NLTK\n",
    "# https://yudiwbs.wordpress.com/2018/02/20/pos-tagger-bahasa-indonesia-dengan-pytho/\n",
    "from nltk.tag import CRFTagger\n",
    "ct = CRFTagger()\n",
    "ct.set_model_file('data/all_indo_man_tag_corpus_model.crf.tagger')\n",
    "\n",
    "hasil = ct.tag_sents([Ti.split()]) # Hati-hati ... Stuktur Data ini adalah \"List-of-Lists\"!!!...\n",
    "hasil = hasil[0]\n",
    "print(hasil)\n",
    "# Hati-hati dengan struktur data inputnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WordNet:\n",
    "\n",
    "<p><img alt=\"\" src=\"images/2_WordNet_Logo.jpg\" style=\"height:100px; width:313px\" /></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Sebuah Lexical database Bahasa Inggris dengan konsep &quot;word sense&quot;</li>\n",
    "\t<li>Diprakarsai oleh George A. Miller di tahun 1980</li>\n",
    "\t<li>WordNet memuat informasi hubungan semantic antar kata.</li>\n",
    "</ul>\n",
    "\n",
    "<p>[<a href=\"https://www.slideshare.net/govindraj15/wordnet-27805299\" target=\"_blank\">Image Source</a>]</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Struktur Wordnet:</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/2_WordNet_Structure.png\" style=\"height:338px; width:599px\" /></p>\n",
    "\n",
    "<p>[<a href=\"https://www.slideshare.net/govindraj15/wordnet-27805299\" target=\"_blank\">Image Source</a>]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><u><strong>Beberapa istilah penting:</strong></u></p>\n",
    "\n",
    "<ol>\n",
    "\t<li><strong>Semantics </strong>: Makna/arti ekspresi manusia melalui bahasa<br />\n",
    "\tNLP hanya bisa berusaha mendapatkan makna <strong>denotasi </strong>dari suatu bahasa.<br />\n",
    "\tKata-kata (<strong>Lexical </strong>terms) yang di olah hanyalah kata baku (dictionary words)</li>\n",
    "\t<li>Dalam Semantic terdapat beberapa konsep:</li>\n",
    "</ol>\n",
    "\n",
    "<ul>\n",
    "\t<li><strong>Polysemy </strong>: Kata dengan makna &gt;1. Contoh: Apple&nbsp;(buah dan merk)</li>\n",
    "\t<li><strong>Synonymy </strong>: Persamaan kata</li>\n",
    "\t<li><strong>Antonymy </strong>: Lawan kata</li>\n",
    "\t<li><strong>Hyponymy </strong>: Khusus ==&gt; Umum, contoh : &quot;merah&quot; adalah hyponym dari &quot;warna&quot;<br />\n",
    "\tHubungan ini di dapat dari taxonomy (hierarchical structure) kata .</li>\n",
    "\t<li><strong>Hypernym </strong>: Umum ==&gt; Khusus, contoh: &quot;warna&quot; adalah hypernymnya &quot;merah&quot;</li>\n",
    "\t<li><strong>Idiom </strong>: istilah yang makna berbeda secara signifikan dibandingkan kata penyusunnya.<br />\n",
    "\tContoh: buah tangan, meja hijau, dll.</li>\n",
    "\t<li><strong>Meronym </strong>: Hubungan sematik karena bagian dari sesuatu. Misal jari meronym tangan dan roda meronym mobil.</li>\n",
    "\t<li><strong>Holonym </strong>: kebalikan meronym, contoh: tangan holonym Jari, dan mobil holonym roda.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><strong>Aplikasi WordNet:</strong></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Word Similarity</li>\n",
    "\t<li>Word Sense Disambiguation (WSD)</li>\n",
    "\t<li>Improving Information Retrieval</li>\n",
    "\t<li>Machine Translation, dsb</li>\n",
    "</ul>\n",
    "<p><strong>WordNet Size:</strong></p>\n",
    "<p><img alt=\"\" src=\"images/2_WordNet_Size.jpg\" style=\"height:300px; width:353px\" /></p>\n",
    "<p>[<a href=\"https://www.slideshare.net/govindraj15/wordnet-27805299\" target=\"_blank\">Image Source</a>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#WordNet Interface - Synonym sets\n",
    "from nltk.corpus import wordnet as wn # Load English WordNet\n",
    "\n",
    "print([sinonim.name() for sinonim in wn.synsets(\"bank\")])\n",
    "\n",
    "# Hasilnya adalah sebuah triplets (<lemma>.<pos>.<number>)\n",
    "# <Lemma> : word’s morphological stem (kata baku/dasar)\n",
    "# <pos ~ part-of-speech> : Atribut kata n-NOUN, v-VERB, a-ADJECTIVE, s-ADJECTIVE SATELLITE, r-ADVERB \n",
    "# <number> : Sense number, index integer (bilangan bulat) \"terurut dari penggunaan yang paling populer\"\n",
    "# http://www.nltk.org/api/nltk.corpus.reader.html?highlight=wordnet#nltk.corpus.reader.wordnet.Lemma.synset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Sinonim bergantung pada Jenis kata # NOUN, VERB, ADJ, ADV\n",
    "print( [s.name() for s in wn.synsets(\"run\", pos=wn.NOUN)[:5]] ) \n",
    "print( [s.name() for s in wn.synsets(\"run\", pos=wn.VERB)[:5]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Definisi suatu kata (membutuhkan parameter input yang spesifik)\n",
    "print(wn.synset('bank.n.08').definition())\n",
    "print(wn.synset('run.n.01').definition())\n",
    "print(wn.synset('run.v.01').definition())\n",
    "# Hati-hati \"synset\" not \"synsets\" \n",
    "# butuh attribut POS (i.e. n,v,a,r, atau s) dan index (00,01,02,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Contoh kalimat untuk suatu kata (butuh triplets sebagai input)\n",
    "print(wn.synset('bank.n.08').examples())\n",
    "print(wn.synset('run.n.01').examples())\n",
    "print(wn.synset('run.v.01').examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aplikasi WordNet : Jarak antar Kata\n",
    "<p>WordNet memiliki beberapa&nbsp;<strong>Words Similarities</strong>, contoh (<strong>thesaurus-based</strong>):</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Path similarity</li>\n",
    "\t<li>Leacock-Chodorow Similarity</li>\n",
    "\t<li>Wu-Palmer Similarity</li>\n",
    "</ul>\n",
    "\n",
    "<ol>\n",
    "\t<li>Thesaurus based similarity menggunakan hirarki (tingkatan) hypernym/hyponym (is-a or subsumption). Dalam hal ini di struktur WordNet.</li>\n",
    "\t<li>Hanya noun-noun (thesaurus-based) similarity bisa dilakukan di wordnet, karena noun dan verb berada di 2 hirarki yg berbeda</li>\n",
    "\t<li>&nbsp;2 kata similar jika &quot;hampir sinonim&quot; atau setidaknya dapat tergantikan dalam konteks yang sama. <strong>Word Relatedness</strong>&nbsp;(WR) != WS, Contoh <em>Love </em>dan <em>hate </em>memiliki relatedness yang besar (sebagai bentuk perasaan), tapi similarity yang kecil.</li>\n",
    "    <li>Similarity != Jarak</li>\n",
    "\t<li>WS berguna untuk aplikasi yang membutuhkan semantic kata, misal sistem QA, IR, Summariztion, &amp; machine translation.</li>\n",
    "</ol>\n",
    "\n",
    "<p><strong>Distributional based</strong> simmilarities (tidak dibahas):</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Resnik Similarity</li>\n",
    "\t<li>Jiang-Conrath Similarity</li>\n",
    "\t<li>Lin Similarity</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Reference</strong>:&nbsp;Dan Jurafsky and James H. Martin&#39;s ubiquitous&nbsp;<a href=\"http://rads.stackoverflow.com/amzn/click/0131873210\" target=\"_blank\">Speech and Language Processing 2nd Edition</a>. Halaman: 652-667 di bab 20 (Computational Lexical Semantics).&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"images/2_WordNet_graph_similarity.jpg\" style=\"height:400px; width:769px\" /></p>\n",
    "[Image Source: Dan Jurafsky and James H. Martin's ubiquitous Speech and Language Processing 2nd Edition.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Path Similarity : shortest path\n",
    "# Path similarity menghitung jumlah edges minimal dari suatu word sense ke word sense lainnya, \n",
    "# Menggunakan struktur data hirarki (graph) seperti WordNet\n",
    "man = wn.synset(\"man.n.01\")\n",
    "boy = wn.synset(\"boy.n.01\")\n",
    "woman = wn.synset(\"woman.n.01\")\n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dime = wn.synset('dime.n.00')\n",
    "\n",
    "a = man.path_similarity(man) \n",
    "b = man.path_similarity(dog)\n",
    "c = dog.path_similarity(cat)\n",
    "d = man.path_similarity(boy)\n",
    "print(a,b,c,d)\n",
    "man.path_similarity(dime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Leacock-Chodorow Similarity (Leacock and Chodorow 1998) : -log(shortest_path_w1_w2)\n",
    "# Warning, slow!. \n",
    "man = wn.synset(\"man.n.01\")\n",
    "woman = wn.synset(\"woman.n.01\")\n",
    "dog = wn.synset('dog.n.01')\n",
    "tree = wn.synset('tree.n.01')\n",
    "\n",
    "a = man.lch_similarity(woman) \n",
    "b = man.lch_similarity(dog)\n",
    "c = dog.lch_similarity(tree)\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Word Similarity by semantics: wupsimilarity\n",
    "# need try-catch\n",
    "man = wn.synset(\"man.n.01\")\n",
    "woman = wn.synset(\"woman.n.01\")\n",
    "boy = wn.synset('boy.n.01')\n",
    "hate = wn.synset('hate.n.01')\n",
    "love = wn.synset('love.n.01')\n",
    "a = man.wup_similarity(boy) \n",
    "b = man.wup_similarity(hate)\n",
    "c = boy.wup_similarity(love)  \n",
    "d = hate.wup_similarity(love)\n",
    "w = man.wup_similarity(woman)\n",
    "print(a,b,c,d,w)\n",
    "# Measured by semantics, d close to 1 (because they are antonyms)\n",
    "# Explanation summary of this distance: https://linguistics.stackexchange.com/a/9164\n",
    "# More theoritical Reference: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3864022/\n",
    "# We will discuss word2vec latter as an alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# WordNet Indonesia?\n",
    "print(wn.lemmas(\"ambisius\", lang='ind'))\n",
    "print(wn.synsets('ambigu', lang='ind'))\n",
    "# This is not the expected behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load secara manual [sangat terbatas & kurang akurat, namun bisa dikembangkan]\n",
    "import taudataNlpTm as tau\n",
    "\n",
    "wn_id = tau.WordNet_id()\n",
    "w1 = 'ambisius'\n",
    "w2 = 'ambigu'\n",
    "print(w1, wn_id[w1], '\\n', w2, wn_id[w2])\n",
    "# Masih load sebagai dictionary belum sebagai class/object\n",
    "# WordNet seluruh Bahasa: http://compling.hss.ntu.edu.sg/omw/  - MIT license\n",
    "# https://stackoverflow.com/questions/31478152/how-to-use-the-language-option-in-synsets-nltk-if-you-load-a-wordnet-manually\n",
    "# http://nullege.com/codes/search/nltk.corpus.reader.wordnet.WordNetCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#WordNet from textBlob\n",
    "from textblob import Word\n",
    "word = Word(\"plant\")\n",
    "word.synsets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# berbagai definisi \"plant\"\n",
    "word.definitions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# related Lemma\n",
    "plant = word.synsets[1]\n",
    "print(plant.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hypernyms : Umum ==> khusus\n",
    "# e.g. contoh organisme adalah plant\n",
    "plant.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hyponyms : khusus ==> umum\n",
    "# e.g. contoh plant adalah aquatic (plant)\n",
    "plant.hyponyms()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hubungan semantic bagian dari\n",
    "plant.member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Kebalikan Holonym\n",
    "plant.part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Contoh similarity menggunakan TextBlob\n",
    "from textblob.wordnet import Synset\n",
    "octopus = Synset(\"octopus.n.02\")\n",
    "nautilus = Synset('paper_nautilus.n.01')\n",
    "shrimp = Synset('shrimp.n.03')\n",
    "pearl = Synset('pearl.n.01')\n",
    "hate = wn.synset('hate.n.01')\n",
    "love = wn.synset('love.n.01')\n",
    "\n",
    "a = octopus.path_similarity(octopus)  # 1.0\n",
    "b = octopus.path_similarity(nautilus)  # 0.33\n",
    "c = octopus.path_similarity(shrimp)  # 0.11\n",
    "d = octopus.path_similarity(pearl)  \n",
    "e = hate.path_similarity(love)\n",
    "print(a,b,c,d,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aplikasi WordNet: Word Sense Disambiguation - WSD\n",
    "<img alt=\"\" src=\"images/2_cartoon-wsd.jpg\" style=\"height:400px; width:601px\" /></p>\n",
    "<p>[<a href=\"https://fthmb.tqn.com/td3gPXSL4x7TgpacjAveL1y1Xvg=/2123x1412/filters:no_upscale():fill(FFCC00,1)/Getty_syntactic_ambiguity-569743119-57a797a63df78cf459475108.jpg\" target=\"_blank\">image source</a>]</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><strong>Word Sense Disambiguation</strong></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Bertujuan untuk mendapatkan word sense (makna kata) yang tepat &quot;sesuai dengan konteksnya&quot;.&nbsp;</li>\n",
    "\t<li>Contoh aplikasinya penterjemah (machine translation), named entity recognition, Question-Answering system, IR, klasifikasi text, dll.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><strong>WSD in a Nutshell:</strong></p>\n",
    "\n",
    "<p><strong><img alt=\"\" src=\"images/2_WSD.jpg\" style=\"height:300px; width:533px\" /></strong></p>\n",
    "\n",
    "<p>[<a href=\"https://www.slideshare.net/koji_matsuda/entity-linking-meets-word-sense-disambiguation-a-unified-approach\" target=\"_blank\">Image Source</a>]</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Word sense disambiguation : \"book\" - buku dan memesan tiket\n",
    "T1 = 'Please book me a ticket to Jogjakarta'\n",
    "T2 = 'I am going to read this book in the flight'\n",
    "\n",
    "for token in nlp_en(T1):\n",
    "    print(token,token.tag_, end =', ')\n",
    "print()\n",
    "\n",
    "for token in nlp_en(T2):\n",
    "    print(token,token.tag_, end =', ')\n",
    "# perbedaan yang jelas antara VB dan NN pada kata \"book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"images/2_Lesk_Algorithm.jpg\" style=\"height:400px; width:533px\" /></p>\n",
    "\n",
    "<p>[<a href=\"https://image.slidesharecdn.com/advances-in-wsd-aaai-2005-091229133933-phpapp02/95/advances-in-wsd-aaai-2005-41-728.jpg?cb=1262094095\" target=\"_blank\">image source</a>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# A more proper way = Lesk Algorithm\n",
    "# https://en.wikipedia.org/wiki/Lesk_algorithm\n",
    "# Minor Modified from from https://stackoverflow.com/questions/20896278/word-sense-disambiguation-algorithm-in-python\n",
    "\n",
    "bank_1 = 'I went to the bank to deposit my money'\n",
    "bank_2 = 'The river bank was full of dead fishes'\n",
    "\n",
    "# lesk_wsd(sentence, ambiguous_word, pos=None, stem=True, hyperhypo=True)\n",
    "print(\"Context:\", bank_1)\n",
    "answer = tau.lesk_wsd(bank_1,'bank')\n",
    "print(\"Sense:\", answer)\n",
    "print(\"Definition:\",wn.synset(answer).definition(),'\\n')\n",
    "\n",
    "print(\"Context:\", bank_2)\n",
    "answer = tau.lesk_wsd(bank_2,'bank')\n",
    "print(\"Sense:\", answer)\n",
    "print(\"Definition:\",wn.synset(answer).definition(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context:\", T1)\n",
    "answer = tau.lesk_wsd(T1,'book')\n",
    "print(\"Sense:\", answer)\n",
    "print(\"Definition:\",wn.synset(answer).definition(),'\\n')\n",
    "\n",
    "print(\"Context:\", T2)\n",
    "answer = tau.lesk_wsd(bank_2,'book')\n",
    "print(\"Sense:\", answer)\n",
    "print(\"Definition:\",wn.synset(answer).definition(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More alternatives in Python for WSD\n",
    "http://meta-guide.com/software-meta-guide/100-best-github-word-sense-disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>End of Module</h1>\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/2_Linguistic_Joke.jpg\" style=\"height:400px; width:608px\" />"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
